% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/PipeOpTextVectorizer.R
\name{mlr_pipeops_text_vectorizer}
\alias{mlr_pipeops_text_vectorizer}
\alias{PipeOpTextVectorizer}
\title{PipeOpTextVectorizer}
\format{\code{\link{R6Class}} object inheriting from \code{\link{PipeOpTaskPreproc}}/\code{\link{PipeOp}}.}
\description{
Computes a bag-of-word representation from a (set of) columns.
Columns of type \code{character} are split up into words.
Uses the \code{\link[quanteda:dfm]{quanteda::dfm()}} and
\code{\link[quanteda:dfm_trim]{quanteda::dfm_trim()}} functions from the
'quanteda' package.
Parameters specify arguments to 'dfm' and 'dfm_trim', i.e. how to
tokenize the data and how to trim the bag-of-words matrix.
}
\section{Construction}{
\preformatted{PipeOpTextVectorizer$new(id = "text_vectorizer", param_vals = list())
}
\itemize{
\item \code{id} :: \code{character(1)}\cr
Identifier of resulting object, default \code{"text_vectorizer"}.
\item \code{param_vals} :: named \code{list}\cr
List of hyperparameter settings, overwriting the hyperparameter settings that would otherwise be set during construction. Default \code{list()}.
}
}

\section{Input and Output Channels}{

Input and output channels are inherited from \code{\link{PipeOpTaskPreproc}}.

The output is the input \code{\link[mlr3:Task]{Task}} with all affected features converted to a bag-of-words
representation.
}

\section{State}{

The \verb{$state} is a list with element 'cols': A vector of extracted columns.
}

\section{Parameters}{

The parameters are the parameters inherited from \code{\link{PipeOpTaskPreproc}}, as well as:
\itemize{
\item \code{language} :: \code{character(1)}\cr
Language to use for stopword filtering. Needs to be either in
\code{stopwords::stopwords_getlanguages("snowball")} or \code{"smart"}.
'smart' coresponds to \code{stopwords::stopwords(source = "smart")}, which
also removes one-character strings. Default: 'smart'.
\item \code{remove_stopwords} :: \code{logical(1)}\cr
Remove stopwords according to 'language'? Default: \code{TRUE}.
\item \code{tolower} :: \code{logical(1)}\cr
Convert to lower case? Default: \code{TRUE}.
\item \code{remove_punct} :: \code{logical(1)}\cr
See \code{quanteda::tokens}. Default: \code{FALSE}.
\item \code{remove_punct} :: \code{logical(1)}\cr
See \code{quanteda::tokens}. Default: \code{FALSE}.
\item \code{remove_symbols} :: \code{logical(1)}\cr
See \code{quanteda::tokens}. Default: \code{FALSE}.
\item \code{remove_numbers} :: \code{logical(1)}\cr
See \code{quanteda::tokens}. Default: \code{FALSE}.
\item \code{remove_separators} :: \code{logical(1)}\cr
See \code{quanteda::tokens}. Default: \code{TRUE}.
\item \code{sparsity} :: \code{numeric(1)}\cr
Desired sparsity of the 'tfm' matrix. See \code{quanteda::dfm_trim}. Default: \code{NULL}.
\item \code{max_termfreq} :: \code{numeric(1)}\cr
Maximum term frequency in the 'tfm' matrix. See \code{quanteda::dfm_trim}. Default: \code{NULL}.
\item \code{min_termfreq} :: \code{numeric(1)}\cr
Minimum term frequency in the 'tfm' matrix. See \code{quanteda::dfm_trim}. Default: \code{NULL}.
\item \code{termfreq_type} :: \code{character}\cr
How to asess term frequency. See \code{quanteda::dfm_trim}. Default: 'count'.
}
}

\section{Internals}{

Uses the \code{\link[quanteda:dfm]{quanteda::dfm()}} and
\code{\link[quanteda:dfm_trim]{quanteda::dfm_trim()}} functions from the
'quanteda' package.
All columns selected via \code{affect_columns} are concatenated before computing the bag of words.
}

\section{Methods}{

Only methods inherited from \code{\link{PipeOpTaskPreproc}}/\code{\link{PipeOp}}.
}

\examples{
library("mlr3")
library("data.table")
# create some text data
dt = data.table(
  txt = replicate(150, paste0(sample(letters, 3), collapse = " "))
)
task = tsk("iris")$cbind(dt)

pos = po("text_vectorizer", param_vals = list(language = "en"))

pos$train(list(task))[[1]]$data()

one_line_of_iris = task$filter(13)

one_line_of_iris$data()

pos$predict(list(one_line_of_iris))[[1]]$data()
}
\seealso{
Other PipeOps: 
\code{\link{PipeOpEnsemble}},
\code{\link{PipeOpImpute}},
\code{\link{PipeOpTaskPreproc}},
\code{\link{PipeOp}},
\code{\link{mlr_pipeops_boxcox}},
\code{\link{mlr_pipeops_branch}},
\code{\link{mlr_pipeops_chunk}},
\code{\link{mlr_pipeops_classbalancing}},
\code{\link{mlr_pipeops_classifavg}},
\code{\link{mlr_pipeops_classweights}},
\code{\link{mlr_pipeops_colapply}},
\code{\link{mlr_pipeops_collapsefactors}},
\code{\link{mlr_pipeops_copy}},
\code{\link{mlr_pipeops_encodeimpact}},
\code{\link{mlr_pipeops_encodelmer}},
\code{\link{mlr_pipeops_encode}},
\code{\link{mlr_pipeops_featureunion}},
\code{\link{mlr_pipeops_filter}},
\code{\link{mlr_pipeops_fixfactors}},
\code{\link{mlr_pipeops_histbin}},
\code{\link{mlr_pipeops_ica}},
\code{\link{mlr_pipeops_imputehist}},
\code{\link{mlr_pipeops_imputemean}},
\code{\link{mlr_pipeops_imputemedian}},
\code{\link{mlr_pipeops_imputenewlvl}},
\code{\link{mlr_pipeops_imputesample}},
\code{\link{mlr_pipeops_kernelpca}},
\code{\link{mlr_pipeops_learner}},
\code{\link{mlr_pipeops_missind}},
\code{\link{mlr_pipeops_modelmatrix}},
\code{\link{mlr_pipeops_mutate}},
\code{\link{mlr_pipeops_nop}},
\code{\link{mlr_pipeops_pca}},
\code{\link{mlr_pipeops_quantilebin}},
\code{\link{mlr_pipeops_regravg}},
\code{\link{mlr_pipeops_removeconstants}},
\code{\link{mlr_pipeops_scalemaxabs}},
\code{\link{mlr_pipeops_scalerange}},
\code{\link{mlr_pipeops_scale}},
\code{\link{mlr_pipeops_select}},
\code{\link{mlr_pipeops_smote}},
\code{\link{mlr_pipeops_spatialsign}},
\code{\link{mlr_pipeops_subsample}},
\code{\link{mlr_pipeops_unbranch}},
\code{\link{mlr_pipeops_yeojohnson}},
\code{\link{mlr_pipeops}}
}
\concept{PipeOps}
